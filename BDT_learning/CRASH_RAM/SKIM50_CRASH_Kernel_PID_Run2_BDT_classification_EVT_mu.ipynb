{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Photon ID Run 2 BDT classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "#import mplhep as hep\n",
    "#hep.style.use(\"ATLAS\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "import joblib\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"/home/chardong/y_identification/Venv/save_pkl/\"\n",
    "savedir = \"/home/chardong/y_identification/work/save_plots/Py8_yj_jj_train_skim50/evt_mu/\"\n",
    "#datadir = \"/eos/user/m/mdelmast/Data/EGamma/PhotonID/Run2/\"\n",
    "savedirmodel = \"/home/chardong/y_identification/work/BDT_model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#totald = pd.read_pickle(datadir+\"Py8_yj_jj_mc16ade_pd122_train_w.pkl\")\n",
    "#totald = pd.read_pickle(datadir+\"Py8_yj_jj_mc16ade_pd122_train_w_skim.pkl\")\n",
    "totald = pd.read_pickle(datadir+\"Py8_yj_jj_mc16ade_pd122_train_w_skim_50.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shower_shape_var = ['y_Reta',\n",
    "                    'y_Rphi',\n",
    "                    'y_weta2',\n",
    "                    'y_fracs1',\n",
    "                    'y_weta1',\n",
    "                    'y_wtots1',\n",
    "                    'y_Rhad',\n",
    "                    'y_Rhad1',\n",
    "                    'y_Eratio', \n",
    "                    'y_deltae']\n",
    "\n",
    "prcpl_vx = ['evt_mu']       #Principal vertex parametrs, feel free to rocket me if I'm wrong\n",
    "\n",
    "\n",
    "conv_var = [ 'y_convRadius', 'y_convType']\n",
    "\n",
    "kinem_var = ['y_pt', 'y_eta', 'y_phi']\n",
    "\n",
    "#truth_var = ['y_truth_pt', 'y_truth_eta', 'y_truth_pdgId', 'y_truth_mother_pdgId' ]\n",
    "truth_var = ['y_truth_pt', 'y_truth_eta' ]\n",
    "\n",
    "discriminating_var = shower_shape_var + kinem_var + conv_var + prcpl_vx\n",
    "discriminating_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare inputs for training\n",
    "\n",
    "* `discriminating_var` containes the features used in the training\n",
    "* Weights are added Y column to be able to access them after splitting in train and test samples.\n",
    "* `test_size` represents the proportion of the dataset to include in the test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(totald.columns)-set(discriminating_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_var = [\"truth_label\",\n",
    "         \"weight\",\n",
    "         'y_IsTight',\n",
    "         'y_IsLoose',\n",
    "         'evt_mu', \n",
    "        ]\n",
    "\n",
    "Y_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save X and Y datasets with relevant variables\n",
    "\n",
    "* Adding truth variables to X for performance studies, will be removed after splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = totald[discriminating_var+truth_var]\n",
    "Y = totald[Y_var]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into train, validation and test samples\n",
    "\n",
    "* Test dataset size: 20 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_val, x_test, y_train_val, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train + validation set into train and validation\n",
    "\n",
    "* Train and validation are respectively 80% and 20% of 80% of total\n",
    "* Save weights in separate arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_train = y_train[\"weight\"]\n",
    "weight_val   = y_val  [\"weight\"]\n",
    "weight_test  = y_test [\"weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "othervars_train = y_train[['evt_mu', 'y_IsLoose', 'y_IsTight']]\n",
    "othervars_val   = y_val  [['evt_mu', 'y_IsLoose', 'y_IsTight']]\n",
    "othervars_test  = y_test [['evt_mu', 'y_IsLoose', 'y_IsTight']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_train = x_train[['y_truth_pt','y_truth_eta']]\n",
    "truth_val   = x_val  [['y_truth_pt','y_truth_eta']]\n",
    "truth_test  = x_test [['y_truth_pt','y_truth_eta']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_var_drop = list(set(y_train.columns)-{'truth_label'})\n",
    "truth_var_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.drop(truth_var_drop, axis=1)\n",
    "y_test  = y_test.drop(truth_var_drop, axis=1)\n",
    "y_val   = y_val.drop(truth_var_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.drop(truth_var, axis=1)\n",
    "x_test  = x_test.drop(truth_var, axis=1)\n",
    "x_val   = x_val.drop(truth_var, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TRAINING   size = {:8d}'.format(len(y_train)))\n",
    "print('TEST       size = {:8d}'.format(len(y_test)))\n",
    "print('VALIDATION size = {:8d}'.format(len(y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of signal events in test sample     :', len(y_test.query('truth_label == True')))\n",
    "print('Number of background events in test sample :', len(y_test.query('truth_label == False')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.ravel(y_train)\n",
    "y_val = np.ravel(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BDT training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(learning_rate=0.05,  \n",
    "                           num_leaves=35,\n",
    "                           max_depth=-5,\n",
    "                           objective='xentropy',\n",
    "                           n_estimators=1000,\n",
    "                           force_col_wise=True)\n",
    "\n",
    "cb = [lgb.early_stopping(stopping_rounds=10),lgb.log_evaluation(30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          sample_weight = weight_train,\n",
    "          eval_set = [(x_train, y_train), (x_val, y_val)],  \n",
    "          eval_names = ['Train', 'Validation'],\n",
    "          eval_metric = 'xentropy', \n",
    "          eval_sample_weight = [weight_train, weight_val],\n",
    "          callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Saving model to file\n",
    "joblib.dump(model,'/home/chardong/y_identification/work/BDT_model/LGBMClassifier_model_hard_no_loose_lr0.05_35_skim30_Addevtmu.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model from file\n",
    "model_pickle = joblib.load(savedirmodel+\"LGBMClassifier_model_hard_no_loose_lr0.05_35_skim30_Addevtmu.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-entropy evolution during training\n",
    "lgb.plot_metric(model, figsize=(8,6))\n",
    "plt.title('Metric during training')\n",
    "plt.savefig(savedir+'metric_lr_0.09_35_skim50.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance: Numbers of times the feature is used in a model\n",
    "lgb.plot_importance(model, importance_type='split', figsize=(8,6))\n",
    "plt.title('Feature importance: split')\n",
    "plt.savefig(savedir+'AddEvtmu_feature_split_lr_0.09_35_skim50.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(model, importance_type='gain', precision = None, figsize=(8,6))\n",
    "plt.title('Feature importance: gain')\n",
    "plt.savefig(savedir+'AddEvtmu_feature_gain_lr_0.09_35_skim50.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions for test sample, add signal and background scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob_test = model.predict_proba(x_test)\n",
    "\n",
    "df_pred_test = pd.DataFrame(y_pred_prob_test, columns=[\"background_score\", \"signal_score\"])\n",
    "df_pred_test.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.DataFrame(y_test)\n",
    "y_test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "truth_test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "othervars_test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df_test_vars = x_test[kinem_var + conv_var]\n",
    "df_test_vars.reset_index(inplace=True, drop=True)\n",
    "\n",
    "weight_test = pd.DataFrame(weight_test)\n",
    "weight_test.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.concat([df_test_vars,\n",
    "                     weight_test,\n",
    "                     y_test,\n",
    "                     othervars_test,\n",
    "                     truth_test,\n",
    "                     df_pred_test,\n",
    "                    ], axis=1, join='inner', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = list(df_test_vars.columns) + \\\n",
    "            list(weight_test.columns) + \\\n",
    "            list(y_test.columns) + \\\n",
    "            list(othervars_test.columns) + \\\n",
    "            list(truth_test.columns) + \\\n",
    "            list(df_pred_test.columns)\n",
    "df_test.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_pickle(datadir+\"test_sample_hard_scattering_skim50.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BDT output\n",
    "\n",
    "The BDT output has two columns: for each event a score (probability) to belong to class 0 or class 1  (here they are called `background_class` and `signal_class` ) is assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "plt.hist(df_test[(df_test[\"truth_label\"]==0 )][\"signal_score\"],\n",
    "         weights = df_test[(df_test[\"truth_label\"]==0 )][\"weight\"], \n",
    "         bins = 50, log = True, density = True, alpha=0.5, \n",
    "         histtype = 'stepfilled', label='Background', color = 'b')\n",
    "\n",
    "plt.hist(df_test[(df_test[\"truth_label\"]==1 )][\"signal_score\"],\n",
    "         weights = df_test[(df_test[\"truth_label\"]==1 )][\"weight\"], \n",
    "         bins = 50, log = True, density = True, alpha=0.5,\n",
    "         histtype = 'stepfilled', label='Signal', color = 'orange')\n",
    "\n",
    "plt.ylabel('Frequency', fontsize = 14)\n",
    "\n",
    "plt.legend(loc='upper center', fontsize = 14)\n",
    "plt.gca().set(xlabel=\"LightGBM score (probability to be assigned to the signal class)\")\n",
    "\n",
    "plt.savefig(savedir+'AddEvtmu_score_lr_0.09_35_skim50.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curve\n",
    "\n",
    "1) compute signal and background efficiencies for \"official\" cut-based Tight selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_tot = sum( df_test[(df_test[\"truth_label\"] == 1)][\"weight\"] )\n",
    "s_selected = sum( df_test[(df_test[\"truth_label\"] == 1) & (df_test['y_IsTight'].values)][\"weight\"] )\n",
    "s_eff = s_selected / s_tot\n",
    "\n",
    "b_tot = sum( df_test[(df_test[\"truth_label\"] == 0)][\"weight\"] )\n",
    "b_selected = sum( df_test[(df_test[\"truth_label\"] == 0) & (df_test['y_IsTight'].values)][\"weight\"] )\n",
    "b_eff = b_selected / b_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of signal events                   = {s_tot:12.0f}\")\n",
    "print(f\"Number of signal events passing Tight     = {s_selected:12.0f}\")\n",
    "print(f\"Signal efficiency of cut-based Tight      = {100.*s_selected/s_tot:11.2f}%\" )\n",
    "print()\n",
    "print(f\"Number of background events               = {b_tot:12.0f}\")\n",
    "print(f\"Number of background events passing Tight = {b_selected:12.0f}\")\n",
    "print(f\"Background efficiency of cut-based Tight  = {100.*b_selected/b_tot:11.2f}%\" )\n",
    "print(f\"Background rejection of cut-based Tight   = {100.*(1-b_selected/b_tot):11.2f}%\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Plot ROC curve of trained BDT with weighted events, compare to current cut-based Tight selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "mod_disp = RocCurveDisplay.from_estimator(model, x_test, y_test, sample_weight=weight_test, \n",
    "                                          label=\"BDT\", ax=ax) \n",
    "\n",
    "plt.plot(b_eff, s_eff, marker=\"x\", markersize=10, color=\"red\", label = 'Cut-based Tight ID')\n",
    "\n",
    "plt.xlabel('Background efficiency')\n",
    "plt.ylabel('Signal efficiency')\n",
    "\n",
    "#plt.xlim([0.0, 0.15])\n",
    "#plt.ylim([0.65, 1.0])\n",
    "#plt.title('BDT ROC curve - zoom')\n",
    "\n",
    "plt.title('BDT ROC curve')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(savedir+'AddEvtmu_ROC_lr_0.05_35_weight_skim50.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#x_train_sel = x_train.query('y_wtots1 >- 800 & y_weta1 > -800')\n",
    "#x_train_sel.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = x_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "sns.heatmap(corr, vmin=-1, vmax=1, cmap=\"coolwarm\", ax=ax, annot=True, fmt=\".2f\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(savedir+'AddEvtmu_correlations_train_sample_all_skim50.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corr_sig = x_train[(y_train==1)].corr()\n",
    "#corr_bkg = x_train[(y_train==0)].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
