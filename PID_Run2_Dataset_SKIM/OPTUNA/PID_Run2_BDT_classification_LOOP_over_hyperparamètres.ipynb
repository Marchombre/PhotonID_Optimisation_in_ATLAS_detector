{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Photon ID Run 2 BDT classification - Hyperparameter optimation\n",
    "\n",
    "https://github.com/optuna/optuna-examples/blob/main/lightgbm/lightgbm_simple.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import RocCurveDisplay, accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"/home/chardong/y_identification/Venv/save_pkl/\"\n",
    "savedir = \"/home/chardong/y_identification/Venv/save_plots/Py8_yj_jj_train_skim30/\"\n",
    "# Chemin pour enregistrer les fichiers pickle\n",
    "save_path = '/home/chardong/y_identification/Venv/save_pkl/Fudge_Factor/'\n",
    "#datadir = \"/eos/user/m/mdelmast/Data/EGamma/PhotonID/Run2/\"\n",
    "savedirmodel = \"/home/chardong/y_identification/Venv/BDT_model/skim30/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(datadir+\"RAW_data/Py8_yj_jj_mc16ade_pd122_train_w_skim_30.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shower_shape_var = ['y_Reta',\n",
    "                    'y_Rphi',\n",
    "                    'y_weta2',\n",
    "                    'y_fracs1',\n",
    "                    'y_weta1',\n",
    "                    'y_wtots1',\n",
    "                    'y_Rhad',\n",
    "                    'y_Rhad1',\n",
    "                    'y_Eratio', \n",
    "                    'y_deltae']\n",
    "\n",
    "conv_var = [ 'y_convRadius', 'y_convType']\n",
    "\n",
    "kinem_var = ['y_pt', 'y_eta', 'y_phi']\n",
    "\n",
    "truth_var = ['y_truth_pt', 'y_truth_eta' ]\n",
    "\n",
    "discriminating_var = shower_shape_var + kinem_var + conv_var \n",
    "\n",
    "Y_var = list(set(df.columns)-set(discriminating_var+truth_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[discriminating_var+truth_var]\n",
    "Y = df[Y_var]\n",
    "\n",
    "x_train_val, x_test, y_train_val, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.2, random_state=42)\n",
    "\n",
    "weight_train = y_train[\"weight\"]\n",
    "weight_val   = y_val  [\"weight\"]\n",
    "weight_test  = y_test [\"weight\"]\n",
    "\n",
    "Y_var_drop = list(set(Y_var)-{\"truth_label\"})\n",
    "\n",
    "othervars_train = y_train[Y_var_drop]\n",
    "othervars_val   = y_val  [Y_var_drop]\n",
    "othervars_test  = y_test [Y_var_drop]\n",
    "\n",
    "y_train = y_train.drop(Y_var_drop, axis=1)\n",
    "y_test  = y_test .drop(Y_var_drop, axis=1)\n",
    "y_val   = y_val  .drop(Y_var_drop, axis=1)\n",
    "\n",
    "truth_train = x_train[truth_var]\n",
    "truth_val   = x_val  [truth_var]\n",
    "truth_test  = x_test [truth_var]\n",
    "\n",
    "x_train = x_train.drop(truth_var, axis=1)\n",
    "x_test  = x_test .drop(truth_var, axis=1)\n",
    "x_val   = x_val  .drop(truth_var, axis=1)\n",
    "\n",
    "y_train = np.ravel(y_train)\n",
    "y_val   = np.ravel(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plages d'hyperparamètres\n",
    "learning_rates = [0.01, 0.05, 0.1]\n",
    "num_leaves_options = [31, 63, 127]\n",
    "max_depth_options = [-1, -5, -10]\n",
    "n_estimators_options = [100, 500, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7479469, number of negative: 3702534\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.410837 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3576\n",
      "[LightGBM] [Info] Number of data points in the train set: 11182003, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500230 -> initscore=0.000918\n",
      "[LightGBM] [Info] Start training from score 0.000918\n",
      "Params: lr=0.01, leaves=31, depth=-1, estimators=100\n",
      "F1 Score: 0.9074035143522032\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 7479469, number of negative: 3702534\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.311148 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3576\n",
      "[LightGBM] [Info] Number of data points in the train set: 11182003, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500230 -> initscore=0.000918\n",
      "[LightGBM] [Info] Start training from score 0.000918\n",
      "Params: lr=0.01, leaves=31, depth=-1, estimators=500\n",
      "F1 Score: 0.9165804294031134\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 7479469, number of negative: 3702534\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.425398 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3576\n",
      "[LightGBM] [Info] Number of data points in the train set: 11182003, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500230 -> initscore=0.000918\n",
      "[LightGBM] [Info] Start training from score 0.000918\n"
     ]
    }
   ],
   "source": [
    "best_f1 = 0\n",
    "best_params = {}\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for num_leaves in num_leaves_options:\n",
    "        for max_depth in max_depth_options:\n",
    "            for n_estimators in n_estimators_options:\n",
    "                # Définir le modèle avec les hyperparamètres actuels\n",
    "                model = lgb.LGBMClassifier(\n",
    "                    learning_rate=lr,\n",
    "                    num_leaves=num_leaves,\n",
    "                    max_depth=max_depth,\n",
    "                    n_estimators=n_estimators\n",
    "                )\n",
    "                \n",
    "                # Entraîner le modèle\n",
    "                model.fit(x_train, y_train, sample_weight=weight_train)\n",
    "                \n",
    "                # Prédictions sur l'ensemble de validation\n",
    "                y_val_pred_proba = model.predict_proba(x_val)[:, 1]\n",
    "                \n",
    "                # Calcul de la courbe Précision-Rappel\n",
    "                precision, recall, _ = precision_recall_curve(y_val, y_val_pred_proba, sample_weight=weight_val)\n",
    "                f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "                max_f1 = np.max(f1)  # F1-score maximal pour cette configuration\n",
    "                \n",
    "                if max_f1 > best_f1:\n",
    "                    best_f1 = max_f1\n",
    "                    best_params = {\n",
    "                        'learning_rate': lr,\n",
    "                        'num_leaves': num_leaves,\n",
    "                        'max_depth': max_depth,\n",
    "                        'n_estimators': n_estimators\n",
    "                    }\n",
    "\n",
    "                print(f'Params: lr={lr}, leaves={num_leaves}, depth={max_depth}, estimators={n_estimators}')\n",
    "                print(f'F1 Score: {max_f1}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Best F1 Score: {best_f1}')\n",
    "print(f'Best Parameters: {best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting on the validation set\n",
    "z_val = np.dot(x_val, weights) + bias\n",
    "y_val_pred = sigmoid(z_val)\n",
    "y_val_pred = np.where(y_val_pred > 0.5, 1, 0)\n",
    "\n",
    "# Calculate accuracy on the validation set\n",
    "accuracy = np.mean(y_val_pred == y_val)\n",
    "print(f'Validation Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
