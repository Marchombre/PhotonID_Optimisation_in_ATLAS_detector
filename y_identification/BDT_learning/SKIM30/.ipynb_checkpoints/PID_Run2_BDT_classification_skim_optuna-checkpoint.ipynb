{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Photon ID Run 2 BDT classification - Hyperparameter optimation\n",
    "\n",
    "https://github.com/optuna/optuna-examples/blob/main/lightgbm/lightgbm_simple.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "import seaborn as sns\n",
    "\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import RocCurveDisplay, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"/Users/Marco/Data/PhotonID/Run2/\"\n",
    "#datadir = \"/eos/user/m/mdelmast/Data/EGamma/PhotonID/Run2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(datadir+\"Py8_yj_jj_mc16ade_pd122_train_w_skim_30.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shower_shape_var = ['y_Reta',\n",
    "                    'y_Rphi',\n",
    "                    'y_weta2',\n",
    "                    'y_fracs1',\n",
    "                    'y_weta1',\n",
    "                    'y_wtots1',\n",
    "                    'y_Rhad',\n",
    "                    'y_Rhad1',\n",
    "                    'y_Eratio', \n",
    "                    'y_deltae']\n",
    "\n",
    "conv_var = [ 'y_convRadius', 'y_convType']\n",
    "\n",
    "kinem_var = ['y_pt', 'y_eta', 'y_phi']\n",
    "\n",
    "truth_var = ['y_truth_pt', 'y_truth_eta' ]\n",
    "\n",
    "discriminating_var = shower_shape_var + kinem_var + conv_var \n",
    "\n",
    "Y_var = list(set(df.columns)-set(discriminating_var+truth_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[discriminating_var+truth_var]\n",
    "Y = df[Y_var]\n",
    "\n",
    "x_train_val, x_test, y_train_val, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.2, random_state=42)\n",
    "\n",
    "weight_train = y_train[\"weight\"]\n",
    "weight_val   = y_val  [\"weight\"]\n",
    "weight_test  = y_test [\"weight\"]\n",
    "\n",
    "Y_var_drop = list(set(Y_var)-{\"truth_label\"})\n",
    "\n",
    "othervars_train = y_train[Y_var_drop]\n",
    "othervars_val   = y_val  [Y_var_drop]\n",
    "othervars_test  = y_test [Y_var_drop]\n",
    "\n",
    "y_train = y_train.drop(Y_var_drop, axis=1)\n",
    "y_test  = y_test .drop(Y_var_drop, axis=1)\n",
    "y_val   = y_val  .drop(Y_var_drop, axis=1)\n",
    "\n",
    "truth_train = x_train[truth_var]\n",
    "truth_val   = x_val  [truth_var]\n",
    "truth_test  = x_test [truth_var]\n",
    "\n",
    "x_train = x_train.drop(truth_var, axis=1)\n",
    "x_test  = x_test .drop(truth_var, axis=1)\n",
    "x_val   = x_val  .drop(truth_var, axis=1)\n",
    "\n",
    "y_train = np.ravel(y_train)\n",
    "y_val   = np.ravel(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html#sphx-glr-auto-examples-model-selection-plot-precision-recall-py\n",
    "\n",
    "def classification_metric(testy, probs):\n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "    precision, recall, thresholds = precision_recall_curve(testy, probs[:,1])\n",
    "    # convert to f score\n",
    "    fscore = (2 * precision * recall) / (precision + recall)\n",
    "    # locate the index of the largest f score\n",
    "    ix = np.argmax(fscore)\n",
    "    return fscore[ix]\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    model = lgb.LGBMClassifier(learning_rate  = 0.05,  \n",
    "                               num_leaves     = trial.suggest_int(\"num_leaves\", 2, 256), # tries various value trying to get maximum accuracy\n",
    "                               max_depth      = -5,\n",
    "                               objective      = 'xentropy',\n",
    "                               n_estimators   = 10,\n",
    "                               force_col_wise = True,\n",
    "                               verbosity      = -1)\n",
    "\n",
    "    cb = [lgb.early_stopping(stopping_rounds=10),lgb.log_evaluation(30)]\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "          sample_weight = weight_train,\n",
    "          eval_set = [(x_train, y_train), (x_val, y_val)],  \n",
    "          eval_names = ['Train', 'Validation'],\n",
    "          eval_sample_weight = [weight_train, weight_val],\n",
    "          callbacks = cb)\n",
    "    \n",
    "    y_pred_prob_test = model.predict_proba(x_test)\n",
    "    return classification_metric(y_test, y_pred_prob_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-09 15:48:08,468] A new study created in memory with name: no-name-2dc5e323-b92e-4a58-9156-ba2298ebf027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tTrain's cross_entropy: 0.462484\tValidation's cross_entropy: 0.459184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-09 15:48:22,936] Trial 0 finished with value: 0.9718535075139194 and parameters: {'num_leaves': 82}. Best is trial 0 with value: 0.9718535075139194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tTrain's cross_entropy: 0.45765\tValidation's cross_entropy: 0.455261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-09 15:48:45,147] Trial 1 finished with value: 0.9726528948494932 and parameters: {'num_leaves': 237}. Best is trial 1 with value: 0.9726528948494932.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tTrain's cross_entropy: 0.505309\tValidation's cross_entropy: 0.501087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-09 15:48:58,278] Trial 2 finished with value: 0.9551263206816019 and parameters: {'num_leaves': 3}. Best is trial 1 with value: 0.9726528948494932.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tTrain's cross_entropy: 0.45744\tValidation's cross_entropy: 0.455111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-09 15:49:13,988] Trial 3 finished with value: 0.9723755305557058 and parameters: {'num_leaves': 247}. Best is trial 1 with value: 0.9726528948494932.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tTrain's cross_entropy: 0.458147\tValidation's cross_entropy: 0.455591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-09 15:49:29,343] Trial 4 finished with value: 0.9722553938737679 and parameters: {'num_leaves': 212}. Best is trial 1 with value: 0.9726528948494932.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 5\n",
      "Best trial:\n",
      "  Value: 0.9726528948494932\n",
      "  Params: \n",
      "    num_leaves: 237\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=5)\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
