{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Photon ID Run 2 BDT classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "#import mplhep as hep\n",
    "#hep.style.use(\"ATLAS\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "import joblib\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"/home/chardong/y_identification/Venv/save_pkl/\"\n",
    "savedir = \"/home/chardong/y_identification/Venv/save_plots/Py8_yj_jj_train_skim30/\"\n",
    "#datadir = \"/eos/user/m/mdelmast/Data/EGamma/PhotonID/Run2/\"\n",
    "savedirmodel = \"/home/chardong/y_identification/Venv/BDT_model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#totald = pd.read_pickle(datadir+\"Py8_yj_jj_mc16ade_pd122_train_w.pkl\")\n",
    "#totald = pd.read_pickle(datadir+\"Py8_yj_jj_mc16ade_pd122_train_w_skim.pkl\")\n",
    "totald = pd.read_pickle(datadir+\"RAW_data/Py8_yj_jj_mc16ade_pd122_train_w_skim_30.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['y_Reta', 'y_Rphi', 'y_weta2', 'y_fracs1', 'y_weta1', 'y_wtots1',\n",
       "       'y_Rhad', 'y_Rhad1', 'y_Eratio', 'y_deltae', 'y_convRadius',\n",
       "       'y_convType', 'y_pt', 'y_eta', 'y_phi', 'evt_mu', 'y_IsTight',\n",
       "       'y_IsLoose', 'y_truth_pt', 'y_truth_eta', 'weight', 'truth_label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totald.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_noFF_Reta',\n",
       " 'y_noFF_Rphi',\n",
       " 'y_noFF_weta2',\n",
       " 'y_noFF_fracs1',\n",
       " 'y_noFF_weta1',\n",
       " 'y_noFF_f1',\n",
       " 'y_noFF_wtots1',\n",
       " 'y_noFF_Rhad',\n",
       " 'y_noFF_Rhad1',\n",
       " 'y_noFF_Eratio',\n",
       " 'y_noFF_deltae',\n",
       " 'y_pt',\n",
       " 'y_eta',\n",
       " 'y_phi',\n",
       " 'y_convRadius',\n",
       " 'y_convType']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shower_shape_var = ['y_noFF_Reta',\n",
    "                    \n",
    " 'y_noFF_Rphi',\n",
    " 'y_noFF_weta2',\n",
    " 'y_noFF_fracs1',\n",
    " 'y_noFF_weta1',\n",
    " 'y_noFF_f1',\n",
    " 'y_noFF_wtots1',\n",
    " 'y_noFF_Rhad',\n",
    " 'y_noFF_Rhad1',\n",
    " 'y_noFF_Eratio',\n",
    " 'y_noFF_deltae']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "conv_var = [ 'y_convRadius', 'y_convType']\n",
    "\n",
    "kinem_var = ['y_pt', 'y_eta', 'y_phi']\n",
    "\n",
    "#truth_var = ['y_truth_pt', 'y_truth_eta', 'y_truth_pdgId', 'y_truth_mother_pdgId' ]\n",
    "truth_var = ['y_truth_pt', 'y_truth_eta' ]\n",
    "\n",
    "discriminating_var = shower_shape_var + kinem_var + conv_var\n",
    "discriminating_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare inputs for training\n",
    "\n",
    "* `discriminating_var` containes the features used in the training\n",
    "* Weights are added Y column to be able to access them after splitting in train and test samples.\n",
    "* `test_size` represents the proportion of the dataset to include in the test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'evt_mu',\n",
       " 'truth_label',\n",
       " 'weight',\n",
       " 'y_Eratio',\n",
       " 'y_IsLoose',\n",
       " 'y_IsTight',\n",
       " 'y_Reta',\n",
       " 'y_Rhad',\n",
       " 'y_Rhad1',\n",
       " 'y_Rphi',\n",
       " 'y_deltae',\n",
       " 'y_fracs1',\n",
       " 'y_truth_eta',\n",
       " 'y_truth_pt',\n",
       " 'y_weta1',\n",
       " 'y_weta2',\n",
       " 'y_wtots1'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(totald.columns)-set(discriminating_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['truth_label', 'weight', 'y_IsTight', 'y_IsLoose', 'evt_mu']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_var = [\"truth_label\",\n",
    "         \"weight\",\n",
    "         'y_IsTight',\n",
    "         'y_IsLoose',\n",
    "         'evt_mu', \n",
    "        ]\n",
    "\n",
    "Y_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save X and Y datasets with relevant variables\n",
    "\n",
    "* Adding truth variables to X for performance studies, will be removed after splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['y_noFF_Reta', 'y_noFF_Rphi', 'y_noFF_weta2', 'y_noFF_fracs1', 'y_noFF_weta1', 'y_noFF_f1', 'y_noFF_wtots1', 'y_noFF_Rhad', 'y_noFF_Rhad1', 'y_noFF_Eratio', 'y_noFF_deltae'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mtotald\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdiscriminating_var\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mtruth_var\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      2\u001b[0m Y \u001b[38;5;241m=\u001b[39m totald[Y_var]\n",
      "File \u001b[0;32m~/Bureau/Work/vevn-py3.10/lib/python3.10/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/Bureau/Work/vevn-py3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/Bureau/Work/vevn-py3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['y_noFF_Reta', 'y_noFF_Rphi', 'y_noFF_weta2', 'y_noFF_fracs1', 'y_noFF_weta1', 'y_noFF_f1', 'y_noFF_wtots1', 'y_noFF_Rhad', 'y_noFF_Rhad1', 'y_noFF_Eratio', 'y_noFF_deltae'] not in index\""
     ]
    }
   ],
   "source": [
    "X = totald[discriminating_var+truth_var]\n",
    "Y = totald[Y_var]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into train, validation and test samples\n",
    "\n",
    "* Test dataset size: 20 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_val, x_test, y_train_val, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train + validation set into train and validation\n",
    "\n",
    "* Train and validation are respectively 80% and 20% of 80% of total\n",
    "* Save weights in separate arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_train = y_train[\"weight\"]\n",
    "weight_val   = y_val  [\"weight\"]\n",
    "weight_test  = y_test [\"weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "othervars_train = y_train[['evt_mu', 'y_IsLoose', 'y_IsTight']]\n",
    "othervars_val   = y_val  [['evt_mu', 'y_IsLoose', 'y_IsTight']]\n",
    "othervars_test  = y_test [['evt_mu', 'y_IsLoose', 'y_IsTight']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_train = x_train[['y_truth_pt','y_truth_eta']]\n",
    "truth_val   = x_val  [['y_truth_pt','y_truth_eta']]\n",
    "truth_test  = x_test [['y_truth_pt','y_truth_eta']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_var_drop = list(set(y_train.columns)-{'truth_label'})\n",
    "truth_var_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.drop(truth_var_drop, axis=1)\n",
    "y_test  = y_test.drop(truth_var_drop, axis=1)\n",
    "y_val   = y_val.drop(truth_var_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.drop(truth_var, axis=1)\n",
    "x_test  = x_test.drop(truth_var, axis=1)\n",
    "x_val   = x_val.drop(truth_var, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TRAINING   size = {:8d}'.format(len(y_train)))\n",
    "print('TEST       size = {:8d}'.format(len(y_test)))\n",
    "print('VALIDATION size = {:8d}'.format(len(y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of signal events in test sample     :', len(y_test.query('truth_label == True')))\n",
    "print('Number of background events in test sample :', len(y_test.query('truth_label == False')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.ravel(y_train)\n",
    "y_val = np.ravel(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BDT training"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = lgb.LGBMClassifier(learning_rate=0.05,  \n",
    "                           num_leaves=35,\n",
    "                           max_depth=-5,\n",
    "                           objective='xentropy',\n",
    "                           n_estimators=1000,\n",
    "                           force_col_wise=True)\n",
    "\n",
    "cb = [lgb.early_stopping(stopping_rounds=10),lgb.log_evaluation(30)]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.fit(x_train, y_train,\n",
    "          sample_weight = weight_train,\n",
    "          eval_set = [(x_train, y_train), (x_val, y_val)],  \n",
    "          eval_names = ['Train', 'Validation'],\n",
    "          eval_metric = 'xentropy', \n",
    "          eval_sample_weight = [weight_train, weight_val],\n",
    "          callbacks=cb)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " # Saving model to file\n",
    "joblib.dump(model,'/home/chardong/y_identification/Venv/BDT_model/LGBMClassifier_model_hard_no_loose_lr0.05_35_skim30.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model from file\n",
    "model_pickle = joblib.load(savedirmodel+\"LGBMClassifier_model_hard_no_loose_lr0.05_35_skim30.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-entropy evolution during training\n",
    "lgb.plot_metric(model, figsize=(8,6))\n",
    "plt.title('Metric during training')\n",
    "#plt.savefig(savedir+'metric_lr_0.09_35_skim30.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance: Numbers of times the feature is used in a model\n",
    "lgb.plot_importance(model, importance_type='split', figsize=(8,6))\n",
    "plt.title('Feature importance: split')\n",
    "#plt.savefig(savedir+'feature_split_lr_0.09_35_skim30.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(model, importance_type='gain', precision = None, figsize=(8,6))\n",
    "plt.title('Feature importance: gain')\n",
    "#plt.savefig(savedir+'feature_gain_lr_0.09_35_skim30.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions for test sample, add signal and background scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob_test = model.predict_proba(x_test)\n",
    "\n",
    "df_pred_test = pd.DataFrame(y_pred_prob_test, columns=[\"background_score\", \"signal_score\"])\n",
    "df_pred_test.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.DataFrame(y_test)\n",
    "y_test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "truth_test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "othervars_test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df_test_vars = x_test[kinem_var + conv_var]\n",
    "df_test_vars.reset_index(inplace=True, drop=True)\n",
    "\n",
    "weight_test = pd.DataFrame(weight_test)\n",
    "weight_test.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.concat([df_test_vars,\n",
    "                     weight_test,\n",
    "                     y_test,\n",
    "                     othervars_test,\n",
    "                     truth_test,\n",
    "                     df_pred_test,\n",
    "                    ], axis=1, join='inner', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = list(df_test_vars.columns) + \\\n",
    "            list(weight_test.columns) + \\\n",
    "            list(y_test.columns) + \\\n",
    "            list(othervars_test.columns) + \\\n",
    "            list(truth_test.columns) + \\\n",
    "            list(df_pred_test.columns)\n",
    "df_test.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_pickle(datadir+\"/test_sample_hard_scattering/test_sample_hard_scattering_skim30.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BDT output\n",
    "\n",
    "The BDT output has two columns: for each event a score (probability) to belong to class 0 or class 1  (here they are called `background_class` and `signal_class` ) is assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "plt.hist(df_test[(df_test[\"truth_label\"]==0 )][\"signal_score\"],\n",
    "         weights = df_test[(df_test[\"truth_label\"]==0 )][\"weight\"], \n",
    "         bins = 50, log = True, density = True, alpha=0.5, \n",
    "         histtype = 'stepfilled', label='Background', color = 'b')\n",
    "\n",
    "plt.hist(df_test[(df_test[\"truth_label\"]==1 )][\"signal_score\"],\n",
    "         weights = df_test[(df_test[\"truth_label\"]==1 )][\"weight\"], \n",
    "         bins = 50, log = True, density = True, alpha=0.5,\n",
    "         histtype = 'stepfilled', label='Signal', color = 'orange')\n",
    "\n",
    "plt.ylabel('Frequency', fontsize = 14)\n",
    "\n",
    "plt.legend(loc='upper center', fontsize = 14)\n",
    "plt.gca().set(xlabel=\"LightGBM score (probability to be assigned to the signal class)\")\n",
    "\n",
    "#plt.savefig(savedir+'score_lr_0.09_35_skim30.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curve\n",
    "\n",
    "1) compute signal and background efficiencies for \"official\" cut-based Tight selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_tot = sum( df_test[(df_test[\"truth_label\"] == 1)][\"weight\"] )\n",
    "s_selected = sum( df_test[(df_test[\"truth_label\"] == 1) & (df_test['y_IsTight'].values)][\"weight\"] )\n",
    "s_eff = s_selected / s_tot\n",
    "\n",
    "b_tot = sum( df_test[(df_test[\"truth_label\"] == 0)][\"weight\"] )\n",
    "b_selected = sum( df_test[(df_test[\"truth_label\"] == 0) & (df_test['y_IsTight'].values)][\"weight\"] )\n",
    "b_eff = b_selected / b_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of signal events                   = {s_tot:12.0f}\")\n",
    "print(f\"Number of signal events passing Tight     = {s_selected:12.0f}\")\n",
    "print(f\"Signal efficiency of cut-based Tight      = {100.*s_selected/s_tot:11.2f}%\" )\n",
    "print()\n",
    "print(f\"Number of background events               = {b_tot:12.0f}\")\n",
    "print(f\"Number of background events passing Tight = {b_selected:12.0f}\")\n",
    "print(f\"Background efficiency of cut-based Tight  = {100.*b_selected/b_tot:11.2f}%\" )\n",
    "print(f\"Background rejection of cut-based Tight   = {100.*(1-b_selected/b_tot):11.2f}%\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Plot ROC curve of trained BDT with weighted events, compare to current cut-based Tight selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "mod_disp = RocCurveDisplay.from_estimator(model, x_test, y_test, sample_weight=weight_test, \n",
    "                                          label=\"BDT\", ax=ax) \n",
    "\n",
    "plt.plot(b_eff, s_eff, marker=\"x\", markersize=10, color=\"red\", label = 'Cut-based Tight ID')\n",
    "\n",
    "plt.xlabel('Background efficiency')\n",
    "plt.ylabel('Signal efficiency')\n",
    "\n",
    "#plt.xlim([0.0, 0.15])\n",
    "#plt.ylim([0.65, 1.0])\n",
    "#plt.title('BDT ROC curve - zoom')\n",
    "\n",
    "plt.title('BDT ROC curve')\n",
    "plt.legend()\n",
    "\n",
    "#plt.savefig(savedir+'ROC_lr_0.05_35_weight_skim30.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#x_train_sel = x_train.query('y_wtots1 >- 800 & y_weta1 > -800')\n",
    "#x_train_sel.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = x_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "sns.heatmap(corr, vmin=-1, vmax=1, cmap=\"coolwarm\", ax=ax, annot=True, fmt=\".2f\")\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig(savedir+'correlations_train_sample_all_skim30.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corr_sig = x_train[(y_train==1)].corr()\n",
    "#corr_bkg = x_train[(y_train==0)].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
