{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Photon ID Run 2 BDT classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "#import mplhep as hep\n",
    "#hep.style.use(\"ATLAS\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "import joblib\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"/home/chardong/y_identification/Venv/save_pkl/\"\n",
    "savedir = \"/home/chardong/y_identification/Venv/save_plots/Py8_yj_jj_train_skim30/evt_mu_BDTnoMU/\"\n",
    "#datadir = \"/eos/user/m/mdelmast/Data/EGamma/PhotonID/Run2/\"\n",
    "savedirmodel = \"/home/chardong/y_identification/Venv/BDT_model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#totald = pd.read_pickle(datadir+\"Py8_yj_jj_mc16ade_pd122_train_w.pkl\")\n",
    "#totald = pd.read_pickle(datadir+\"Py8_yj_jj_mc16ade_pd122_train_w_skim.pkl\")\n",
    "totald = pd.read_pickle(datadir+\"RAW_data/Py8_yj_jj_mc16ade_pd122_train_w_skim_30.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading BDT model \n",
    "model_skim30 = joblib.load(savedirmodel+\"skim30/LGBMClassifier_model_hard_no_loose_lr0.05_35_skim30.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_Reta',\n",
       " 'y_Rphi',\n",
       " 'y_weta2',\n",
       " 'y_fracs1',\n",
       " 'y_weta1',\n",
       " 'y_wtots1',\n",
       " 'y_Rhad',\n",
       " 'y_Rhad1',\n",
       " 'y_Eratio',\n",
       " 'y_deltae',\n",
       " 'y_pt',\n",
       " 'y_eta',\n",
       " 'y_phi',\n",
       " 'y_convRadius',\n",
       " 'y_convType',\n",
       " 'evt_mu']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shower_shape_var = ['y_Reta',\n",
    "                    'y_Rphi',\n",
    "                    'y_weta2',\n",
    "                    'y_fracs1',\n",
    "                    'y_weta1',\n",
    "                    'y_wtots1',\n",
    "                    'y_Rhad',\n",
    "                    'y_Rhad1',\n",
    "                    'y_Eratio', \n",
    "                    'y_deltae']\n",
    "\n",
    "prcpl_vx = ['evt_mu']       #Principal vertex parametrs, feel free to rocket me if I'm wrong\n",
    "\n",
    "\n",
    "conv_var = [ 'y_convRadius', 'y_convType']\n",
    "\n",
    "kinem_var = ['y_pt', 'y_eta', 'y_phi']\n",
    "\n",
    "#truth_var = ['y_truth_pt', 'y_truth_eta', 'y_truth_pdgId', 'y_truth_mother_pdgId' ]\n",
    "truth_var = ['y_truth_pt', 'y_truth_eta' ]\n",
    "\n",
    "discriminating_var = shower_shape_var + kinem_var + conv_var + prcpl_vx\n",
    "discriminating_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare inputs for training\n",
    "\n",
    "* `discriminating_var` containes the features used in the training\n",
    "* Weights are added Y column to be able to access them after splitting in train and test samples.\n",
    "* `test_size` represents the proportion of the dataset to include in the test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'truth_label',\n",
       " 'weight',\n",
       " 'y_IsLoose',\n",
       " 'y_IsTight',\n",
       " 'y_truth_eta',\n",
       " 'y_truth_pt'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(totald.columns)-set(discriminating_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['truth_label', 'weight', 'y_IsTight', 'y_IsLoose', 'evt_mu']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_var = [\"truth_label\",\n",
    "         \"weight\",\n",
    "         'y_IsTight',\n",
    "         'y_IsLoose',\n",
    "         'evt_mu', \n",
    "        ]\n",
    "\n",
    "Y_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save X and Y datasets with relevant variables\n",
    "\n",
    "* Adding truth variables to X for performance studies, will be removed after splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = totald[discriminating_var+truth_var]\n",
    "Y = totald[Y_var]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into train, validation and test samples\n",
    "\n",
    "* Test dataset size: 20 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_val, x_test, y_train_val, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train + validation set into train and validation\n",
    "\n",
    "* Train and validation are respectively 80% and 20% of 80% of total\n",
    "* Save weights in separate arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_train = y_train[\"weight\"]\n",
    "weight_val   = y_val  [\"weight\"]\n",
    "weight_test  = y_test [\"weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "othervars_train = y_train[['evt_mu', 'y_IsLoose', 'y_IsTight']]\n",
    "othervars_val   = y_val  [['evt_mu', 'y_IsLoose', 'y_IsTight']]\n",
    "othervars_test  = y_test [['evt_mu', 'y_IsLoose', 'y_IsTight']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_train = x_train[['y_truth_pt','y_truth_eta']]\n",
    "truth_val   = x_val  [['y_truth_pt','y_truth_eta']]\n",
    "truth_test  = x_test [['y_truth_pt','y_truth_eta']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_IsTight', 'weight', 'evt_mu', 'y_IsLoose']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_var_drop = list(set(y_train.columns)-{'truth_label'})\n",
    "truth_var_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.drop(truth_var_drop, axis=1)\n",
    "y_test  = y_test.drop(truth_var_drop, axis=1)\n",
    "y_val   = y_val.drop(truth_var_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.drop(truth_var, axis=1)\n",
    "x_test  = x_test.drop(truth_var, axis=1)\n",
    "x_val   = x_val.drop(truth_var, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING   size = 11182003\n",
      "TEST       size =  3494377\n",
      "VALIDATION size =  2795501\n"
     ]
    }
   ],
   "source": [
    "print('TRAINING   size = {:8d}'.format(len(y_train)))\n",
    "print('TEST       size = {:8d}'.format(len(y_test)))\n",
    "print('VALIDATION size = {:8d}'.format(len(y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of signal events in test sample     : 2338410\n",
      "Number of background events in test sample : 1155967\n"
     ]
    }
   ],
   "source": [
    "print('Number of signal events in test sample     :', len(y_test.query('truth_label == True')))\n",
    "print('Number of background events in test sample :', len(y_test.query('truth_label == False')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.ravel(y_train)\n",
    "y_val = np.ravel(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BDT training"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_skim30_Addevtmu = lgb.LGBMClassifier(learning_rate=0.05,  \n",
    "                           num_leaves=35,\n",
    "                           max_depth=-5,\n",
    "                           objective='xentropy',\n",
    "                           n_estimators=1000,\n",
    "                           force_col_wise=True)\n",
    "\n",
    "cb = [lgb.early_stopping(stopping_rounds=10),lgb.log_evaluation(30)]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_skim30_Addevtmu.fit(x_train, y_train,\n",
    "          sample_weight = weight_train,\n",
    "          eval_set = [(x_train, y_train), (x_val, y_val)],  \n",
    "          eval_names = ['Train', 'Validation'],\n",
    "          eval_metric = 'xentropy', \n",
    "          eval_sample_weight = [weight_train, weight_val],\n",
    "          callbacks=cb)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " # Saving model to file\n",
    "joblib.dump(model_skim30_Addevtmu,'/home/chardong/y_identification/Venv/BDT_model/LGBMClassifier_model_hard_no_loose_lr0.05_35_skim30_Addevtmu.pkl')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Loading model from file\n",
    "model_skim30_Addevtmu = joblib.load(savedirmodel+\"skim30/LGBMClassifier_model_hard_no_loose_lr0.05_35_skim30_Addevtmu.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Cross-entropy evolution during training\n",
    "lgb.plot_metric(model_skim30_Addevtmu, figsize=(8,6))\n",
    "plt.title('Metric during training')\n",
    "#plt.savefig(savedir+'Addevtmu_metric_lr_0.09_35_skim30.pdf')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Feature importance: Numbers of times the feature is used in a model\n",
    "lgb.plot_importance(model_skim30_Addevtmu, importance_type='split', figsize=(8,6))\n",
    "plt.title('Feature importance: split')\n",
    "#plt.savefig(savedir+'AddEvtmu_feature_split_lr_0.09_35_skim30.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lgb.plot_importance(model_skim30_Addevtmu, importance_type='gain', precision = None, figsize=(8,6))\n",
    "plt.title('Feature importance: gain')\n",
    "#plt.savefig(savedir+'AddEvtmu_feature_gain_lr_0.09_35_skim30.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions for test sample, add signal and background scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features_ is 15 and input n_features is 16",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_pred_prob_test \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_skim30\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m df_pred_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(y_pred_prob_test, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackground_score\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msignal_score\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      4\u001b[0m df_pred_test\u001b[38;5;241m.\u001b[39mreset_index(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Bureau/Work/vevn-py3.10/lib/python3.10/site-packages/lightgbm/sklearn.py:1253\u001b[0m, in \u001b[0;36mLGBMClassifier.predict_proba\u001b[0;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[0m\n\u001b[1;32m   1241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_proba\u001b[39m(\n\u001b[1;32m   1242\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1243\u001b[0m     X: _LGBM_ScikitMatrixLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m   1251\u001b[0m ):\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Docstring is set after definition, using a template.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1253\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpred_leaf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_leaf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpred_contrib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_contrib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   1262\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_objective) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (raw_score \u001b[38;5;129;01mor\u001b[39;00m pred_leaf \u001b[38;5;129;01mor\u001b[39;00m pred_contrib):\n\u001b[1;32m   1264\u001b[0m         _log_warning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot compute class probabilities or labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1265\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdue to the usage of customized objective function.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1266\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning raw scores instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Bureau/Work/vevn-py3.10/lib/python3.10/site-packages/lightgbm/sklearn.py:937\u001b[0m, in \u001b[0;36mLGBMModel.predict\u001b[0;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[0m\n\u001b[1;32m    935\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    936\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_features \u001b[38;5;241m!=\u001b[39m n_features:\n\u001b[0;32m--> 937\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of features of the model must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    938\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatch the input. Model n_features_ is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    939\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput n_features is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    940\u001b[0m \u001b[38;5;66;03m# retrive original params that possibly can be used in both training and prediction\u001b[39;00m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;66;03m# and then overwrite them (considering aliases) with params that were passed directly in prediction\u001b[39;00m\n\u001b[1;32m    942\u001b[0m predict_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_params(stage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features_ is 15 and input n_features is 16"
     ]
    }
   ],
   "source": [
    "y_pred_prob_test = model_skim30.predict_proba(x_test)\n",
    "\n",
    "df_pred_test = pd.DataFrame(y_pred_prob_test, columns=[\"background_score\", \"signal_score\"])\n",
    "df_pred_test.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.DataFrame(y_test)\n",
    "y_test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "truth_test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "othervars_test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df_test_vars = x_test[kinem_var + conv_var]\n",
    "df_test_vars.reset_index(inplace=True, drop=True)\n",
    "\n",
    "weight_test = pd.DataFrame(weight_test)\n",
    "weight_test.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_Addevtmu_BDTnoMu = pd.concat([df_test_vars,\n",
    "                     weight_test,\n",
    "                     y_test,\n",
    "                     othervars_test,\n",
    "                     truth_test,\n",
    "                     df_pred_test,\n",
    "                    ], axis=1, join='inner', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = list(df_test_vars.columns) + \\\n",
    "            list(weight_test.columns) + \\\n",
    "            list(y_test.columns) + \\\n",
    "            list(othervars_test.columns) + \\\n",
    "            list(truth_test.columns) + \\\n",
    "            list(df_pred_test.columns)\n",
    "df_test_Addevtmu_BDTnoMu.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_Addevtmu_BDTnoMu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_Addevtmu_BDTnoMu.to_pickle(datadir+\"df_test_sample_hard_scattering/df_test_Addevtmu_BDTnoMu_test_sample_hard_scattering_skim30.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BDT output\n",
    "\n",
    "The BDT output has two columns: for each event a score (probability) to belong to class 0 or class 1  (here they are called `background_class` and `signal_class` ) is assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "plt.hist(df_test_Addevtmu_BDTnoMu[(df_test_Addevtmu_BDTnoMu[\"truth_label\"]==0 )][\"signal_score\"],\n",
    "         weights = df_test_Addevtmu_BDTnoMu[(df_test_Addevtmu_BDTnoMu[\"truth_label\"]==0 )][\"weight\"], \n",
    "         bins = 50, log = True, density = True, alpha=0.5, \n",
    "         histtype = 'stepfilled', label='Background', color = 'b')\n",
    "\n",
    "plt.hist(df_test_Addevtmu_BDTnoMu[(df_test_Addevtmu_BDTnoMu[\"truth_label\"]==1 )][\"signal_score\"],\n",
    "         weights = df_test_Addevtmu_BDTnoMu[(df_test_Addevtmu_BDTnoMu[\"truth_label\"]==1 )][\"weight\"], \n",
    "         bins = 50, log = True, density = True, alpha=0.5,\n",
    "         histtype = 'stepfilled', label='Signal', color = 'orange')\n",
    "\n",
    "plt.ylabel('Frequency', fontsize = 14)\n",
    "\n",
    "plt.legend(loc='upper center', fontsize = 14)\n",
    "plt.gca().set(xlabel=\"LightGBM score (probability to be assigned to the signal class)\")\n",
    "\n",
    "#plt.savefig(savedir+'AddEvtmu_BDTnoMu_score_lr_0.09_35_skim30.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curve\n",
    "\n",
    "1) compute signal and background efficiencies for \"official\" cut-based Tight selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_tot = sum( df_test_Addevtmu_BDTnoMu[(df_test_Addevtmu_BDTnoMu[\"truth_label\"] == 1)][\"weight\"] )\n",
    "s_selected = sum( df_test_Addevtmu_BDTnoMu[(df_test_Addevtmu_BDTnoMu[\"truth_label\"] == 1) & (df_test_Addevtmu_BDTnoMu['y_IsTight'].values)][\"weight\"] )\n",
    "s_eff = s_selected / s_tot\n",
    "\n",
    "b_tot = sum( df_test_Addevtmu_BDTnoMu[(df_test_Addevtmu_BDTnoMu[\"truth_label\"] == 0)][\"weight\"] )\n",
    "b_selected = sum( df_test_Addevtmu_BDTnoMu[(df_test_Addevtmu_BDTnoMu[\"truth_label\"] == 0) & (df_test_Addevtmu_BDTnoMu['y_IsTight'].values)][\"weight\"] )\n",
    "b_eff = b_selected / b_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of signal events                   = {s_tot:12.0f}\")\n",
    "print(f\"Number of signal events passing Tight     = {s_selected:12.0f}\")\n",
    "print(f\"Signal efficiency of cut-based Tight      = {100.*s_selected/s_tot:11.2f}%\" )\n",
    "print()\n",
    "print(f\"Number of background events               = {b_tot:12.0f}\")\n",
    "print(f\"Number of background events passing Tight = {b_selected:12.0f}\")\n",
    "print(f\"Background efficiency of cut-based Tight  = {100.*b_selected/b_tot:11.2f}%\" )\n",
    "print(f\"Background rejection of cut-based Tight   = {100.*(1-b_selected/b_tot):11.2f}%\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Plot ROC curve of trained BDT with weighted events, compare to current cut-based Tight selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "mod_disp = RocCurveDisplay.from_estimator(model_skim30, x_test, y_test, sample_weight=weight_test, \n",
    "                                          label=\"BDT\", ax=ax) \n",
    "\n",
    "plt.plot(b_eff, s_eff, marker=\"x\", markersize=10, color=\"red\", label = 'Cut-based Tight ID')\n",
    "\n",
    "plt.xlabel('Background efficiency')\n",
    "plt.ylabel('Signal efficiency')\n",
    "\n",
    "#plt.xlim([0.0, 0.15])\n",
    "#plt.ylim([0.65, 1.0])\n",
    "#plt.title('BDT ROC curve - zoom')\n",
    "\n",
    "plt.title('BDT ROC curve')\n",
    "plt.legend()\n",
    "\n",
    "#plt.savefig(savedir+'AddEvtmu_BDTnoMu_ROC_lr_0.05_35_weight_skim30.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#x_train_sel = x_train.query('y_wtots1 >- 800 & y_weta1 > -800')\n",
    "#x_train_sel.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = x_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "sns.heatmap(corr, vmin=-1, vmax=1, cmap=\"coolwarm\", ax=ax, annot=True, fmt=\".2f\")\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig(savedir+'AddEvtmu_BDTnoMu_correlations_train_sample_all_skim30.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corr_sig = x_train[(y_train==1)].corr()\n",
    "#corr_bkg = x_train[(y_train==0)].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
