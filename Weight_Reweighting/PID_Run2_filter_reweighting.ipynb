{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Photon ID Run 2 filter and reweighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import uproot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"/Users/Marco/Data/PhotonID/Run2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/Marco/Data/PhotonID/Run2/Py8_yj_mc16ade_pd122.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_yj \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatadir\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPy8_yj_mc16ade_pd122.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df_jj \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(datadir\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPy8_jj_mc16ade_pd122.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Bureau/Work/vevn-py3.10/lib/python3.10/site-packages/pandas/io/pickle.py:185\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m4    4    9\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    184\u001b[0m excs_to_catch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[0;32m--> 185\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Bureau/Work/vevn-py3.10/lib/python3.10/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/Marco/Data/PhotonID/Run2/Py8_yj_mc16ade_pd122.pkl'"
     ]
    }
   ],
   "source": [
    "df_yj = pd.read_pickle(datadir+\"Py8_yj_mc16ade_pd122.pkl\")\n",
    "df_jj = pd.read_pickle(datadir+\"Py8_jj_mc16ade_pd122.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter datasets for true photons and true jets reconstructed as photons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_ph(data):\n",
    "    return data[(data['y_truth_pdgId'] == 22) & (abs(data['y_truth_mother_pdgId']) < 100)]\n",
    "\n",
    "def true_bkg(data):\n",
    "    return data[(abs(data['y_truth_pdgId']) != 11) & ((data['y_truth_pdgId'] != 22) | \n",
    "                ((data['y_truth_pdgId'] == 22) & (abs(data['y_truth_mother_pdgId']) > 100))) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = true_ph(df_yj)\n",
    "bkg = true_bkg(df_jj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptmin = 20\n",
    "ptmax = 1000\n",
    "nbin = 49\n",
    "dpt = int((ptmax-ptmin)/nbin)\n",
    "\n",
    "bins_pt = np.linspace(ptmin,ptmax,nbin)\n",
    "\n",
    "plt.hist(sig['y_pt'], weights = sig['mcTotWeight'],\n",
    "         bins = bins_pt, histtype = 'stepfilled', alpha = 0.5, label = 'True $\\gamma$ (reco)', log = True)\n",
    "\n",
    "plt.hist(bkg['y_pt'], weights = bkg['mcTotWeight'],\n",
    "         bins = bins_pt, histtype = 'stepfilled', alpha = 0.5, label = 'Fake $\\gamma$ (reco)', log = True)\n",
    "\n",
    "plt.hist(sig['y_truth_pt'], weights = sig['mcTotWeight'],\n",
    "         bins = bins_pt, histtype = 'stepfilled', alpha = 0.5, label = 'True $\\gamma$ (true)', log = True)\n",
    "\n",
    "plt.hist(bkg['y_truth_pt'], weights = bkg['mcTotWeight'],\n",
    "         bins = bins_pt, histtype = 'stepfilled', alpha = 0.5, label = 'Fake $\\gamma$ (true)', log = True)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('$p_T$ [GeV]')\n",
    "plt.ylabel('Events / {} GeV'.format(dpt))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify true photon origin (direct vs brem photons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_all = plt.hist(sig['y_truth_pt'], \n",
    "                 weights = sig['mcTotWeight'],\n",
    "                 histtype = 'step', log = True, bins = bins_pt, label=\"all $\\gamma$\")\n",
    "\n",
    "h_dir = plt.hist(sig[(sig['y_truth_type']==14)]['y_truth_pt'], \n",
    "                 weights = sig[(sig['y_truth_type']==14)]['mcTotWeight'],\n",
    "                 histtype = 'step', log = True, bins = bins_pt, label=\"direct $\\gamma$\")\n",
    "\n",
    "h_bre = plt.hist(sig[(sig['y_truth_type']!=14)]['y_truth_pt'], \n",
    "                 weights = sig[(sig['y_truth_type']!=14)]['mcTotWeight'],\n",
    "                 histtype = 'step', log = True, bins = bins_pt, label=\"brem $\\gamma$\")\n",
    "\n",
    "plt.xlabel('$p_{T, true}$ [GeV]')\n",
    "plt.ylabel('Events / {} GeV'.format(dpt))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ntot = sum(sig[(sig[\"y_truth_pt\"]<1000.)]['mcTotWeight'])\n",
    "ntot = sum(h_all[0])\n",
    "ndir = sum(h_dir[0])\n",
    "nbre = sum(h_bre[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Fraction of direct photons = {}'.format(ndir/ntot))\n",
    "print('Fraction of brem photons   = {}'.format(nbre/ntot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event preselections (as in legacy HH->yybb Run 2 analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove brem photons from signal sample, only keep hard-scattering events (similar to H->yy photons)\n",
    "sig = sig[(sig[\"y_truth_type\"]==14)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutflow_sig = [len(sig)]\n",
    "cutflow_bkg = [len(bkg)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 GeV < pt < 1 TeV\n",
    "sig = sig.drop(sig.index[((sig['y_pt']) < 20.) | ((sig['y_pt']) > 1000.)], axis = 0, inplace = False)\n",
    "bkg = bkg.drop(bkg.index[((bkg['y_pt']) < 20.) | ((bkg['y_pt']) > 1000.)], axis = 0, inplace = False)\n",
    "cutflow_sig.append(len(sig))\n",
    "cutflow_bkg.append(len(bkg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 > 0.005\n",
    "sig = sig[(sig['y_f1']>=0.005)]\n",
    "bkg = bkg[(bkg['y_f1']>=0.005)]\n",
    "cutflow_sig.append(len(sig))\n",
    "cutflow_bkg.append(len(bkg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e277 > 0.1\n",
    "sig = sig[(sig['y_e277']>0.1)]\n",
    "bkg = bkg[(bkg['y_e277']>0.1)]\n",
    "cutflow_sig.append(len(sig))\n",
    "cutflow_bkg.append(len(bkg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loose preselection on eta to eliminate jet outliers (photon candidates are defined up to |eta|=2.37, and exclusing 1.37<|eta|<1.51)\n",
    "sig = sig.drop(sig.index[((sig['y_eta']) <= -2.5) | ((sig['y_eta']) > 2.5)], axis = 0, inplace = False)\n",
    "bkg = bkg.drop(bkg.index[((bkg['y_eta']) <= -2.5) | ((bkg['y_eta']) > 2.5)], axis = 0, inplace = False)\n",
    "cutflow_sig.append(len(sig))\n",
    "cutflow_bkg.append(len(bkg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presels = [\"Initial\", \"20<pT<1000 GeV\", \"f1>0.005\", \"e277>0.1\", \"eta\"]\n",
    "print(\"Cutflow           N(sig)    dN(sig)  frac(sig)      N(bkg)  dN(bkg) frac(bkg)\")\n",
    "print(\"-\"*77)\n",
    "for i,(cut,nsig,nbkg) in enumerate(zip(presels,cutflow_sig,cutflow_bkg)):\n",
    "    dnsig = 0\n",
    "    dnbkg = 0\n",
    "    if i>0:\n",
    "        dnsig = cutflow_sig[i-1]-cutflow_sig[i] \n",
    "        dnbkg = cutflow_bkg[i-1]-cutflow_bkg[i] \n",
    "    print(f\"{cut:15s} {nsig:8d} {dnsig:10d} {100*dnsig/cutflow_sig[0]:8.3f}%     {nbkg:8d} {dnbkg:8d} {100*dnbkg/cutflow_bkg[0]:8.3f}% \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background sample reweighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-indexing dataframes to improve processing\n",
    "sig_presel = sig.set_index(np.arange(0,len(sig)), drop = True)\n",
    "bkg_presel = bkg.set_index(np.arange(0,len(bkg)), drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of preselected signal events     =',len(sig_presel))\n",
    "print('Number of preselected background events =',len(bkg_presel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_presel.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\eta$ reweighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etamin = -2.5\n",
    "etamax =  2.5\n",
    "nbins_eta = 50\n",
    "eta_bins = np.linspace(etamin,etamax,nbins_eta+1)\n",
    "\n",
    "h_eta_sig = plt.hist(sig_presel['y_eta'], weights=sig_presel['mcTotWeight'],\n",
    "                     histtype='step', log=True, bins=eta_bins, label = r'True $\\gamma$ from $\\gamma-j$ sample')\n",
    "\n",
    "h_eta_bkg = plt.hist(bkg_presel['y_eta'], weights=bkg_presel['mcTotWeight'],\n",
    "                     histtype='step', log=True, bins=eta_bins, label = r'True jets as $\\gamma$, from $j-j$ sample')\n",
    "\n",
    "plt.xlabel('$\\eta$')\n",
    "plt.ylabel('Events')\n",
    "plt.legend(loc ='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight(n_sig, n_bkg):\n",
    "    try :\n",
    "        assert (len(n_sig) == len (n_bkg))\n",
    "    except:\n",
    "        print(\"ERROR Arrays have different lengths\")\n",
    "    weight = n_sig / n_bkg\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_w = weight(h_eta_sig[0], h_eta_bkg[0])\n",
    "eta_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_bins = h_eta_sig[1]\n",
    "eta_bins_centers = (eta_bins[:-1]+eta_bins[1:])/2\n",
    "\n",
    "plt.step(eta_bins_centers, h_eta_sig[0]       , linewidth = '1', label = r'True $\\gamma$')\n",
    "plt.step(eta_bins_centers, h_eta_bkg[0]*eta_w , linewidth = '1', label = r'True jets as $\\gamma$, $\\eta$ reweighted')\n",
    "\n",
    "plt.xlabel('$\\eta$')\n",
    "plt.ylabel('Events')\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute weight bin index correponsing to each events in datasets \n",
    "bin_idx_bkg_eta = np.digitize(bkg_presel['y_eta'], eta_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map corresponding weight, add to dataframe\n",
    "idx_bkg_eta = pd.Series(bin_idx_bkg_eta)\n",
    "dfw_bkg_eta = idx_bkg_eta.map({i+1: eta_w[i] for i in range(nbins_eta)}) \n",
    "bkg_presel['etaWeight'] = dfw_bkg_eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_presel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.any(np.isnan(bkg_presel['etaWeight']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $p_T$ reweighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "ptmin = 20.\n",
    "ptmax = 1000.\n",
    "nbins_pt = 40\n",
    "\n",
    "x = np.linspace(log(ptmin),log(ptmax),nbins_pt+1)\n",
    "bins_pt = np.exp(x)\n",
    "print(bins_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_pt_sig = plt.hist(sig_presel['y_pt'], weights=sig_presel['mcTotWeight'],\n",
    "                     histtype='step', log=True, bins=bins_pt, label = r'True $\\gamma$ from $\\gamma-j$ sample')\n",
    "\n",
    "h_pt_bkg = plt.hist(bkg_presel['y_pt'], weights=bkg_presel['mcTotWeight']*bkg_presel['etaWeight'],\n",
    "                     histtype='step', log=True, bins=bins_pt, label = r'True jets as $\\gamma$, from $j-j$ sample')\n",
    "\n",
    "\n",
    "plt.xlabel('$p_T [GeV]$')\n",
    "plt.ylabel('Events')\n",
    "plt.title('Plot $p_T$')\n",
    "plt.legend(loc ='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_w = weight(h_pt_sig[0], h_pt_bkg[0])\n",
    "pt_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_bins = h_pt_sig[1]\n",
    "pt_bins_centers = (pt_bins[:-1]+pt_bins[1:])/2\n",
    "\n",
    "plt.step(pt_bins_centers, h_pt_sig[0]      , linewidth = '1', label = r'True $\\gamma$')\n",
    "plt.step(pt_bins_centers, h_pt_bkg[0]*pt_w , linewidth = '1', label = r'True jets as $\\gamma$, $p_T$ reweighted')\n",
    "\n",
    "plt.xlabel('$\\eta$')\n",
    "plt.ylabel('Events')\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute weight bin index correponsing to each events in datasets \n",
    "bin_idx_bkg_pt = np.digitize(bkg_presel['y_pt'], pt_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map corresponding weight, add to dataframe\n",
    "idx_bkg_pt = pd.Series(bin_idx_bkg_pt)\n",
    "dfw_bkg_pt = idx_bkg_pt.map({i+1: pt_w[i] for i in range(nbins_pt)}) \n",
    "bkg_presel['ptWeight'] = dfw_bkg_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_presel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total weight as product of eta and pt weight\n",
    "bkg_presel['totWeight'] = bkg_presel['mcTotWeight']*bkg_presel['etaWeight']*bkg_presel['ptWeight']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reweighted $\\eta$ and $p_T$ plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sig_presel['y_eta'], weights = sig_presel['mcTotWeight'], \n",
    "         histtype='step', log=True, bins=eta_bins, label = r'True $\\gamma$')\n",
    "\n",
    "plt.hist(bkg_presel['y_eta'], weights = bkg_presel['totWeight'], \n",
    "         histtype='step', log=True, bins=eta_bins, label = r'True jets as $\\gamma$, $\\eta$  and $p_T$ reweighted')\n",
    "\n",
    "plt.xlabel('$\\eta$')\n",
    "plt.ylabel('Events')\n",
    "plt.legend(loc ='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sig_presel['y_pt'], weights = sig_presel['mcTotWeight'], \n",
    "         histtype='step', log=True, bins=pt_bins, label = r'True $\\gamma$')\n",
    "\n",
    "plt.hist(bkg_presel['y_pt'], weights = bkg_presel['totWeight'], \n",
    "         histtype='step', log=True, bins=pt_bins, label = r'True jets as $\\gamma$, $\\eta$  and $p_T$ reweighted')\n",
    "\n",
    "plt.xlabel('$p_T$ [GeV]')\n",
    "plt.ylabel('Events')\n",
    "plt.legend(loc ='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save preselected dataframes with weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_presel.to_pickle(datadir+\"Py8_yj_mc16ade_pd122_train_w.pkl\")\n",
    "bkg_presel.to_pickle(datadir+\"Py8_jj_mc16ade_pd122_train_w.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "dt = t-t0\n",
    "print(f\"Notebook executed in {int(dt//60):d}\\'{int(dt%60):d}\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
